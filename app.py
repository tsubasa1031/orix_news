import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import datetime
import time

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚ªãƒªãƒƒã‚¯ã‚¹ãƒ»ãƒãƒ•ã‚¡ãƒ­ãƒ¼ã‚º ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚",
    page_icon="âš¾",
    layout="wide"
)

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®š ---
def assign_category(text):
    text = text.replace(" ", "")  # ç©ºç™½é™¤å»ã—ã¦ãƒãƒƒãƒãƒ³ã‚°ã—ã‚„ã™ãã™ã‚‹
    keywords = {
        "å¥‘ç´„ãƒ»ç§»ç±": ["å¥‘ç´„", "æ›´æ”¹", "ç§»ç±", "FA", "ãƒˆãƒ¬ãƒ¼ãƒ‰", "æ–°åŠ å…¥", "é€€å›£", "æˆ¦åŠ›å¤–", "ãƒ‰ãƒ©ãƒ•ãƒˆ", "ç²å¾—", "ãƒã‚¹ãƒ†ã‚£ãƒ³ã‚°", "è‚²æˆ", "æ”¯é…ä¸‹", "å¹´ä¿¸", "äººçš„è£œå„Ÿ"],
        "æ€ªæˆ‘ãƒ»èª¿æ•´": ["æ€ªæˆ‘", "æ•…éšœ", "æ‰‹è¡“", "é›¢è„±", "å¾©å¸°", "èª¿æ•´", "æŠ¹æ¶ˆ", "ç™»éŒ²", "ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³", "ç—›", "é•å’Œæ„Ÿ", "ãƒªãƒãƒ“ãƒª"],
        "çƒå›£ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆ": ["ãƒ­ã‚´", "ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ", "ã‚¤ãƒ™ãƒ³ãƒˆ", "ãƒ•ã‚¡ãƒ³", "ãƒã‚±ãƒƒãƒˆ", "ã‚°ãƒƒã‚º", "ã‚¹ãƒãƒ³ã‚µãƒ¼", "ãƒã‚¹ã‚³ãƒƒãƒˆ", "ã‚­ãƒ£ãƒ³ãƒ—", "äººäº‹", "ã‚³ãƒ¼ãƒ", "ç›£ç£"],
        "è©¦åˆãƒ»çµæœ": ["è©¦åˆ", "å‹", "è² ", "æœ¬å¡æ‰“", "å®‰æ‰“", "ç™»æ¿", "å…ˆç™º", "ã‚µãƒ¨ãƒŠãƒ©", "å®Œå°", "æ‰“ç‡", "é˜²å¾¡ç‡", "ã‚¹ã‚³ã‚¢", "é€Ÿå ±", "ç´…ç™½æˆ¦"]
    }
    
    for category, words in keywords.items():
        if any(word in text for word in words):
            return category
    return "ãã®ä»–ãƒ‹ãƒ¥ãƒ¼ã‚¹"

# --- 1. ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•° (Google News RSSã‹ã‚‰å–å¾—) ---
@st.cache_data(ttl=1800)  # 30åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã‚¢ã‚¯ã‚»ã‚¹è² è·ã‚’è»½æ¸›
def load_data():
    # æƒ…å ±é‡ã‚’å¢—ã‚„ã™ãŸã‚ã€è¤‡æ•°ã®åˆ‡ã‚Šå£ã§æ¤œç´¢ã‚’è¡Œã†
    search_queries = [
        "ã‚ªãƒªãƒƒã‚¯ã‚¹+ãƒãƒ•ã‚¡ãƒ­ãƒ¼ã‚º",
        "ã‚ªãƒªãƒƒã‚¯ã‚¹+å¥‘ç´„æ›´æ”¹",
        "ã‚ªãƒªãƒƒã‚¯ã‚¹+ç§»ç±",
        "ã‚ªãƒªãƒƒã‚¯ã‚¹+æ–°å¤–å›½äºº",
        "ã‚ªãƒªãƒƒã‚¯ã‚¹+ãƒ•ã‚¡ãƒ¼ãƒ "
    ]
    
    all_news_list = []
    seen_links = set() # é‡è¤‡æ’é™¤ç”¨ã®ã‚»ãƒƒãƒˆ
    
    with st.spinner('è¤‡æ•°ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†ä¸­...'):
        for query in search_queries:
            url = f"https://news.google.com/rss/search?q={query}&hl=ja&gl=JP&ceid=JP:ja"
            
            try:
                response = requests.get(url, timeout=10)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, "xml")
                items = soup.find_all("item")
                
                for item in items:
                    title = item.title.text
                    
                    # --- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¼·åŒ–: ä»–çƒå›£æƒ…å ±ã®é™¤å¤– ---
                    # ã‚¿ã‚¤ãƒˆãƒ«ã«ã€Œã‚ªãƒªãƒƒã‚¯ã‚¹ã€ã¾ãŸã¯ã€Œãƒãƒ•ã‚¡ãƒ­ãƒ¼ã‚ºã€ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    # (Google Newsã¯é–¢é€£æ€§ã®ä½ã„è¨˜äº‹ã‚‚æ‹¾ã†ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€ã“ã“ã§å³å¯†ã«åˆ¤å®šã—ã¾ã™)
                    if "ã‚ªãƒªãƒƒã‚¯ã‚¹" not in title and "ãƒãƒ•ã‚¡ãƒ­ãƒ¼ã‚º" not in title:
                        continue

                    link = item.link.text
                    
                    if link in seen_links:
                        continue
                    seen_links.add(link)

                    pub_date_str = item.pubDate.text
                    description = item.description.text
                    
                    # --- æ—¥ä»˜å‡¦ç†ã®æ”¹å–„ ---
                    # RSSã®æ—¥ä»˜æ–‡å­—åˆ—ã‚’datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›ï¼ˆã‚½ãƒ¼ãƒˆç”¨ï¼‰
                    try:
                        timestamp = pd.to_datetime(pub_date_str)
                        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’æ—¥æœ¬æ™‚é–“ã«å¤‰æ›ï¼ˆGoogle Newsã¯GMTã®å ´åˆãŒå¤šã„ï¼‰
                        if timestamp.tzinfo is not None:
                            timestamp = timestamp.tz_convert('Asia/Tokyo')
                        display_date = timestamp.strftime('%Y-%m-%d %H:%M')
                    except:
                        timestamp = datetime.datetime.now()
                        display_date = pub_date_str

                    # descriptionã®HTMLé™¤å»ã¨è¦ç´„ä½œæˆ
                    summary_soup = BeautifulSoup(description, "html.parser")
                    summary_text = summary_soup.get_text()[:100] + "..." if summary_soup.get_text() else "è©³ç´°ã¯ã‚ã‚Šã¾ã›ã‚“"

                    # ãƒ‹ãƒ¥ãƒ¼ã‚¹æä¾›å…ƒæŠ½å‡º
                    source = "News"
                    clean_title = title
                    if " - " in title:
                        parts = title.rsplit(" - ", 1)
                        clean_title = parts[0]
                        source = parts[1]

                    category = assign_category(clean_title + summary_text)

                    all_news_list.append({
                        "timestamp": timestamp,   # ã‚½ãƒ¼ãƒˆç”¨ã®datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
                        "date": display_date,     # è¡¨ç¤ºç”¨ã®æ–‡å­—åˆ—
                        "category": category,
                        "media": source,
                        "title": clean_title,
                        "summary": summary_text,
                        "link": link,
                    })
                
                time.sleep(0.5)

            except Exception as e:
                print(f"Query '{query}' failed: {e}")
                continue

    if not all_news_list:
        return pd.DataFrame([
            {"timestamp": pd.Timestamp.now(), "date": "-", "category": "Error", "media": "-", "title": "ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼", "summary": "å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚", "link": "#"}
        ])

    df = pd.DataFrame(all_news_list)
    
    # --- æ™‚ç³»åˆ—ã‚½ãƒ¼ãƒˆ ---
    # timestampã‚«ãƒ©ãƒ ã‚’ä½¿ã£ã¦æ–°ã—ã„é †ï¼ˆé™é †ï¼‰ã«ã‚½ãƒ¼ãƒˆ
    df = df.sort_values("timestamp", ascending=False).reset_index(drop=True)
        
    return df

df = load_data()

# --- 2. ã‚µã‚¤ãƒ‰ãƒãƒ¼ (ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°) ---
st.sidebar.title("ğŸ” æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")

# ã‚½ãƒ¼ãƒˆé †ã®åˆ‡ã‚Šæ›¿ãˆæ©Ÿèƒ½ã‚’è¿½åŠ 
sort_order = st.sidebar.radio("ä¸¦ã³é †", ["æ–°ã—ã„é †", "å¤ã„é †"], horizontal=True)

if sort_order == "å¤ã„é †":
    df = df.sort_values("timestamp", ascending=True).reset_index(drop=True)
else:
    df = df.sort_values("timestamp", ascending=False).reset_index(drop=True)

if not df.empty:
    categories = sorted(df["category"].unique())
    if "ãã®ä»–ãƒ‹ãƒ¥ãƒ¼ã‚¹" in categories:
        categories.remove("ãã®ä»–ãƒ‹ãƒ¥ãƒ¼ã‚¹")
        categories.append("ãã®ä»–ãƒ‹ãƒ¥ãƒ¼ã‚¹")

    selected_categories = st.sidebar.multiselect(
        "ãƒˆãƒ”ãƒƒã‚¯ï¼ˆå†…å®¹ï¼‰ã§çµã‚Šè¾¼ã¿",
        categories,
        default=categories
    )
    
    search_query = st.sidebar.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ (ä¾‹: å‰ç”°è¼æ˜Ÿ)")
    
    filtered_df = df[df["category"].isin(selected_categories)]
    
    if search_query:
        filtered_df = filtered_df[
            filtered_df["title"].str.contains(search_query, case=False) | 
            filtered_df["summary"].str.contains(search_query, case=False)
        ]
else:
    filtered_df = df

# --- 3. ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("âš¾ ã‚ªãƒªãƒƒã‚¯ã‚¹ãƒ»ãƒãƒ•ã‚¡ãƒ­ãƒ¼ã‚º æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹")
st.caption("Google News RSSã‚ˆã‚Šè‡ªå‹•åé›†ãƒ»åˆ†é¡ï¼ˆè¤‡æ•°ã‚½ãƒ¼ã‚¹çµ±åˆç‰ˆï¼‰")

if st.button("ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ›´æ–°"):
    load_data.clear()
    st.rerun()

st.markdown(f"æœ€æ–°è¨˜äº‹: **{len(filtered_df)}** ä»¶")

view_mode = st.radio("è¡¨ç¤ºå½¢å¼:", ["ã‚«ãƒ¼ãƒ‰è¡¨ç¤º", "ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"], horizontal=True)
st.divider()

if not filtered_df.empty:
    if view_mode == "ã‚«ãƒ¼ãƒ‰è¡¨ç¤º":
        for index, row in filtered_df.iterrows():
            label_prefix = ""
            if row['category'] == "å¥‘ç´„ãƒ»ç§»ç±":
                label_prefix = "ğŸ’°"
            elif row['category'] == "æ€ªæˆ‘ãƒ»èª¿æ•´":
                label_prefix = "ğŸ¥"
            elif row['category'] == "çƒå›£ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆ":
                label_prefix = "ğŸŸï¸"
            elif row['category'] == "è©¦åˆãƒ»çµæœ":
                label_prefix = "âš¾"
            else:
                label_prefix = "ğŸ“°"

            with st.expander(f"{label_prefix} ã€{row['category']}ã€‘ {row['title']}", expanded=True):
                st.caption(f"ğŸ“… {row['date']} | ğŸ¢ {row['media']}")
                st.write(row['summary'])
                st.link_button("è¨˜äº‹ã‚’èª­ã‚€ ğŸ”—", row['link'])
                
    elif view_mode == "ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«":
        st.dataframe(
            filtered_df,
            column_config={
                "date": "æ—¥æ™‚",
                "category": "ãƒˆãƒ”ãƒƒã‚¯",
                "media": "ãƒ¡ãƒ‡ã‚£ã‚¢",
                "title": "è¦‹å‡ºã—",
                "summary": "è¦ç´„",
                "link": st.column_config.LinkColumn("ãƒªãƒ³ã‚¯", display_text="è¨˜äº‹ã‚’é–‹ã")
            },
            use_container_width=True,
            hide_index=True
        )
else:
    st.warning("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# --- 4. ãƒ•ãƒƒã‚¿ãƒ¼ ---
st.markdown("---")
st.caption("Powered by Google News RSS")
